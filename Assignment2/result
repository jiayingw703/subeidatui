1.2
2857
6666
20000
training loss for batch size 500 0.011983, training time 25777.086020 ms
training loss for batch size 1500 0.012017, training time 68090.219975 ms
training loss for batch size 3500 0.011968, training time 198168.068886 ms

1.3
validation accuracy for decay_efficient 0.0: 0.990000
validation accuracy for decay_efficient 0.001: 0.980000
validation accuracy for decay_efficient 0.1: 0.980000
validation accuracy for decay_efficient 1.0: 0.980000


1.4
Normal equation result:
validation accuracy: 0.960000,test accuracy:0.931034 ,time_ms:0.541925
0.0808064


---------------------------right-------------------------------------------------------
	1.2
2857
6666
20000
training loss for batch size 500 0.011969, training time 24790.424109 ms
training loss for batch size 1500 0.011969, training time 94317.959785 ms
training loss for batch size 3500 0.011968, training time 211499.012947 ms

	1.3
validation accuracy for decay_efficient 0.0: 0.980000
validation accuracy for decay_efficient 0.001: 0.990000
validation accuracy for decay_efficient 0.1: 0.980000
validation accuracy for decay_efficient 1.0: 0.970000

validation accuracy for decay_efficient 0.0: 0.980000, MSE: 0.014457
validation accuracy for decay_efficient 0.001: 0.980000, MSE: 0.014367
validation accuracy for decay_efficient 0.1: 0.980000, MSE: 0.015733
validation accuracy for decay_efficient 1.0: 0.970000, MSE: 0.018267



	1.4
SGD result:
training_MSE: 0.011980, val_accuracy: 0.980000, test_accuracy: 0.965517, time_ms: 47808.624983

Normal equation result:
training_MSE:0.0115438, validation accuracy: 0.960000,test accuracy:0.931034 ,time_ms:0.567913
--------------------------------------------------------------------------------------
//////////////2_1////////////////////////
Tuning learning rate by validation data for cross entropy.
('learning rate:', '0.5', ' Validation Final loss:', 0.058395155)
('learning rate:', '0.1', ' Validation Final loss:', 0.053102799)
('learning rate:', '0.05', ' Validation Final loss:', 0.05395861)
('learning rate:', '0.01', ' Validation Final loss:', 0.052766904)
('learning rate:', '0.005', ' Validation Final loss:', 0.054244801)
('learning rate:', '0.001', ' Validation Final loss:', 0.070887208)
('learning rate:', '0.0005', ' Validation Final loss:', 0.086825043)
('learning rate:', '0.0001', ' Validation Final loss:', 0.16411825)
('learning rate for min validation cross entropy:', '0.01')


Tuning learning rate by validation data for classification.
('learning rate:', '0.5', ' Validation Final classification:', 0.0)
('learning rate:', '0.1', ' Validation Final classification:', 0.0)
('learning rate:', '0.05', ' Validation Final classification:', 0.0)
('learning rate:', '0.01', ' Validation Final classification:', 0.98)
('learning rate:', '0.005', ' Validation Final classification:', 0.98)
('learning rate:', '0.001', ' Validation Final classification:', 0.96)
('learning rate:', '0.0005', ' Validation Final classification:', 0.95)
('learning rate:', '0.0001', ' Validation Final classification:', 0.95)
('learning rate for max validation accuracy classification:', '0.01')

By runing different learning rate, we decide to use 0.01

2.1.3
Logistic Regression: train accuracy: 0.995714, validation accuracy: 0.990000, test accuracy: 0.979310


